{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class='bar_title'></div>\n",
    "\n",
    "*Introduction to Data Science*\n",
    "\n",
    "# Combining Data and Tidy Data\n",
    "\n",
    "Gunther Gust<br>\n",
    "Chair for Enterprise AI\n",
    "\n",
    "Winter Semester 24/25\n",
    "\n",
    "<img src='https://github.com/GuntherGust/tds2_data/blob/main/images/d3.png?raw=true' style='width:20%; float:left;' /> <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/GuntherGust/tds2_data/blob/main/images/CAIDASlogo.png?raw=true' style='width:20%; float:left;' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "\n",
    "- ## Combining Data\n",
    "\n",
    "    - ### Merging DataFrames\n",
    "    - ### Joining DataFrames\n",
    "    - ### Concatenating DataFrames\n",
    "\n",
    "- ## Tidy Data\n",
    "- ## Real-world Case Study\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Combining Data\n",
    "\n",
    "There are 3 main ways of combining DataFrames together: Merging, Joining and Concatenating. In this lecture we will discuss these 3 methods with examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Merging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The `pd.merge` function implements a number of types of joins: one-to-one, many-to-one, and many-to-many. All three types of joins are accessed via an identical call to the `pd.merge` interface; the type of join performed depends on the form of the input data. We'll start with some simple examples of the three types of merges, and discuss detailed options a bit later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are different types of merges you can perform: inner, outer, left and right. The following picture describes what each method means.\n",
    "\n",
    "<img src='images\\join_options.png' style='width:50%; float:left;' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue', 'Tim'],\n",
    "                    'group': ['Accounting', 'Engineering',\n",
    "                              'Engineering', 'HR', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue', 'Anne'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014, 2006]})\n",
    "display(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df3 = pd.merge(df1, df2, on= \"employee\")\n",
    "display(df1, df2, df3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If the column name is identical in both original dataframes, you don't need to pass the `on=` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b = pd.merge(df1, df2)\n",
    "df3b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Left join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3c = pd.merge(df1, df2, how= \"left\")\n",
    "df3c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Right join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3d = pd.merge(df1, df2, how= \"right\")\n",
    "df3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (Full) outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3e = pd.merge(df1, df2, how= \"outer\")\n",
    "df3e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The result of the merge is a new DataFrame that combines the information from the two inputs. Notice that the order of entries in each column is not necessarily maintained: in this case, the order of the employee column differs between df1 and df2, and the pd.merge function correctly accounts for this. Additionally, keep in mind that the merge in general discards the index, except in the special case of merges by index (see the left_index and right_index keywords)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One-to-Many Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__One to one join:__\n",
    "\n",
    "<img src='images\\inner_join_one_to_one.png' style='width:80%; float:left;' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__One to many join__:\n",
    "\n",
    "<img src='images\\inner_join_one_to_many.png' style='width:80%; float:left;' />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "One-to-Many joins are joins in which one of the two key columns contains duplicate entries. For the One-to-Many case, the resulting DataFrame will preserve those duplicate entries as appropriate. Consider the following example of a One-to-Many join:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],\n",
    "                    'supervisor': ['Carly', 'Guido', 'Steve']})\n",
    "display(df3, df4, pd.merge(df3, df4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Many-to-Many Joins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Many-to-many joins may be a bit confusing conceptually, but are nevertheless well defined. If the key column in both the left and right arrays contains duplicates, then the result is a many-to-many merge. This will be perhaps most clear with a concrete example. Consider the following, where we have a DataFrame showing one or more skills associated with a particular group. By performing a many-to-many join, we can recover the skills associated with any individual person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame({'group': ['Accounting', 'Accounting',\n",
    "                              'Engineering', 'Engineering', 'HR', 'HR'],\n",
    "                    'skills': ['math', 'spreadsheets', 'software', 'math',\n",
    "                               'spreadsheets', 'organization']})\n",
    "display(df1, df5, pd.merge(df1, df5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Specification of the Merge Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'salary': [70000, 80000, 120000, 90000]})\n",
    "display(df1, df3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#get rid of extra column\n",
    "pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\").drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### Exercise 1\n",
    "\n",
    " The following tables are given:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = pd.DataFrame({\n",
    "    'employee_id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Alice', 'Bob', 'Carol', 'David', 'Eve'],\n",
    "    'department_id': [101, 102, 103, 101, None]\n",
    "})\n",
    "\n",
    "departments = pd.DataFrame({\n",
    "    'department_id': [101, 102, 103, 104],\n",
    "    'department_name': ['Sales', 'Engineering', 'Marketing', 'HR']\n",
    "})\n",
    "\n",
    "projects = pd.DataFrame({\n",
    "    'project_id': ['P1', 'P2', 'P3', 'P4', 'P6'],\n",
    "    'employee_id': [1, 1, 2, 3, 6],\n",
    "    'project_name': ['Market Analysis', 'Sales Strategy', 'Product Design', 'Campaign', 'Special Project']\n",
    "})\n",
    "\n",
    "display(employees, departments, projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " What kind of join(s) should be performed in order to get the following result? Is it a one to one or a one to many or a many to many join? Recreate the joined table.\n",
    "\n",
    "\n",
    "\n",
    " <img src='images\\merged_table_lecture_exercise.png' style='width:70%; float:left;' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Joining\n",
    "\n",
    "For convenience, Pandas includes the `DataFrame.join()` method, which performs an index-based merge without extra keywords. This is mostly a simplification of the already discussed `merge` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1a = df1.set_index('employee')\n",
    "df2a = df2.set_index('employee')\n",
    "display(df1a, df2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df1a.join(df2a)\n",
    "\n",
    "# instead of: pd.merge(df1a, df2a, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df1a.join(df2a, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concatenation\n",
    "\n",
    "Concatenation is all about glueing DataFrames together. Just remember that the dimensions need to match along the axis you’re concatenating on. You can use `pd.concat` and provide a list of DataFrames or Series objects to concatenate them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                        'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                        'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                        'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                        index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                        'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                        'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                        'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                         index=[4, 5, 6, 7]) \n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                        'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                        'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                        'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                        index=[8, 9, 10, 11])\n",
    "\n",
    "display(df1, df2, df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Along the Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images\\concat_axis0.avif' style='width:50%; float:left;' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([df1,df2,df3]) # default: axis=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Along the Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images\\concat_axis1.avif' style='width:50%; float:left;' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([df1,df2,df3],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(If the indexes of the dataframes are identical, no `NaN` values are created. But with overlapping indices, using `pd.merge()` / `join()` is preferable.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Control Questions: Mentimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tidy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We will learn a consistent way to organise data in Python, an organisation called __tidy data__. Getting your data into this format requires some upfront work, but that work pays off in the long term. Once you have tidy data and pandas data frames, you will spend much less time munging data from one representation to another, allowing you to spend more time on the analytic questions at hand.\n",
    "\n",
    "This chapter will give you a practical introduction to tidy data and the accompanying tools in the `pandas` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "You can represent the same underlying data in multiple ways. The example below shows the same data organised in four different ways. Each dataset shows the same values of four variables *country*, *year*, *population*, and *cases*, but each dataset organises the values in a different way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://raw.githubusercontent.com/vhaus63/ids_data/refs/heads/main/\"\n",
    "table1 = pd.read_csv(\"{}table1.csv\".format(base_url))\n",
    "table2 = pd.read_csv(\"{}table2.csv\".format(base_url))\n",
    "table3 = pd.read_csv(\"{}table3.csv\".format(base_url))\n",
    "table4a = pd.read_csv(\"{}table4a.csv\".format(base_url))\n",
    "table4b = pd.read_csv(\"{}table4b.csv\".format(base_url))\n",
    "table5 = pd.read_csv(\"{}table5.csv\".format(base_url), dtype = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "display(table1) # cases and population in separate columns\n",
    "display(table2) # type of measurement in one column, count in the other\n",
    "display(table3) # rate=cases/population in one column\n",
    "\n",
    "# Spread across two DataFrames\n",
    "display(table4a)  # cases\n",
    "display(table4b)  # population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivating example\n",
    "\n",
    "Compute the `rate` for `table1`, `table2`, and `table4a` + `table4b`.\n",
    "    You will need to perform four operations:\n",
    "1. Extract the number of TB cases per country per year.\n",
    "2. Extract the matching population per country per year.\n",
    "3. Divide cases by population, and multiply by 10000.\n",
    "4. Store back in the appropriate place.\n",
    "\n",
    "Which representation is easiest to work with? Which is hardest? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These are all representations of the same underlying data, but they are not equally easy to use. One dataset, the tidy dataset, will be much easier to work with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "There are three __interrelated rules__ which make a dataset tidy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1.  Each __variable__ must have its own __column.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2.  Each __observation__ must have its own __row.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3.  Each __value__ must have its own __cell.__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why ensure that your data is tidy? There are two __main advantages:__\n",
    "\n",
    "1.  There's a general advantage to picking one __consistent way of storing\n",
    "    data.__ If you have a consistent data structure, it's easier to learn the\n",
    "    tools that work with it because they have an underlying uniformity.\n",
    "\n",
    "2.  There's a specific advantage to placing variables in columns because it allows __Pandas' and NumPy's vectorised nature to shine.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principles of tidy data seem so obvious that you might wonder if you'll ever encounter a dataset that isn't tidy. Unfortunately, however, most data that you will encounter will be untidy. There are two main reasons:\n",
    "\n",
    "1.  Most __people aren't familiar__ with the principles of tidy data, and it's hard to derive them yourself unless you spend a _lot_ of time working with data.\n",
    "\n",
    "1.  Data is often organised to facilitate some __use other than analysis.__ For  example, data is often organised to make entry as easy as possible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This means for most real analyses, you'll need to do some tidying. \n",
    "\n",
    "1. __The first step__ is always to __figure out__ what the variables and observations are. Sometimes this is easy; other times you'll need to consult with the people who originally generated the data.\n",
    "\n",
    "2. The second step is to __resolve one of two common problems:__\n",
    "\n",
    "    1. One variable might be spread across multiple columns.\n",
    "\n",
    "    1. One observation might be scattered across multiple rows.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Typically a dataset will only suffer from one of these problems; To fix these problems, you'll need three functions in pandas: `melt()`, `pivot()`, and `pivot_table()`. There are two additional functions called `stack()` and `unstack()` that use multi-index columns and rows. Pandas provides a guide to [reshaping and pivot tables](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#reshaping) in their user guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "### Longer (`melt()`)\n",
    "\n",
    "A common problem is a dataset where some of the column names are not names of variables, but _values_ of a variable. Take `table4a`: the column names `1999` and `2000` represent values of the `year` variable, the values in the `1999` and `2000` columns represent values of the `cases` variable, and each row represents two observations, not one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table4a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To tidy a dataset like this, we need to __stack__ the offending columns into a new pair of variables. To describe that operation we need three parameters:\n",
    "\n",
    "* The set of columns whose names are identifier variables, not values. In this example,\n",
    "  `country` is the identifier column and the value columns are `1999` and `2000`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "* The name of the variable to move the column names to. Here it is `year`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "* The name of the variable to move the column values to. Here it's `cases`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Together those parameters generate the call to `melt()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table4a.melt(['country'], var_name = \"year\", value_name = \"cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`year` and `cases` do not exist in `table4a` so we put their names in quotes.\n",
    "\n",
    "In the final result, the pivoted columns are dropped, and we get new `year` and `cases` columns. Otherwise, the relationships between the original variables are preserved. Visually, this is shown in Figure \\@ref(fig:tidy-gather).\n",
    "\n",
    "`melt()` makes datasets longer (imagine melting icecream down the cone) by increasing the number of rows and decreasing the number of columns. I don’t believe it makes sense to describe a dataset as being in “long form”. Length is a relative term, and you can only say that dataset A is longer than dataset B.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use `melt()` to tidy `table4b` in a similar fashion. The only difference is the variable stored in the cell values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table4b.melt(['country'], var_name = 'year', value_name = 'population')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To combine the tidied versions of `table4a` and `table4b` into a single DataFrame, we need to use `merge()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy4a = table4a.melt(['country'], var_name = \"year\", value_name = \"cases\")\n",
    "tidy4b = table4b.melt(['country'], var_name = 'year', value_name = 'population')\n",
    "pd.merge(tidy4a, tidy4b, on = ['country', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wider (`pivot()`)\n",
    "\n",
    "`pivot()` is the opposite of `melt()`. You use it when an observation is scattered across multiple rows. For example, take `table2`: an observation is a country in a year, but each observation is spread across two rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To tidy this up, we first analyse the representation in similar way to `melt()`. This time, however, we only need two parameters:\n",
    "\n",
    "* The column to take variable names from. Here, it's `type`.\n",
    "\n",
    "* The column to take values from. Here it's `count`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once we've figured that out, we can use `pivot()`.\n",
    "\n",
    "In this example, we have a multi-column `index` argument and will need to use `pivot_table()`.  With a single column index `pivot()` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2.pivot_table(\n",
    "    index = ['country', 'year'], \n",
    "    columns = 'type', \n",
    "    values = 'count').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As you might have guessed from their names, `pivot()` and `pivot_table()` are complements to `melt()`. `melt()` makes wide tables narrower and longer; `pivot()` and `pivot_table()` makes long tables shorter and wider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Control Questions: Mentimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### Exercise 2\n",
    "\n",
    "\n",
    "\n",
    " You’re given a DataFrame containing survey results from different years, with each year as a separate column. The data currently looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Carol', 'David'],\n",
    "    '2020': [3, 2, 5, None],\n",
    "    '2021': [None, 3, 4, 4],\n",
    "    '2022': [2, 5, None, 3]\n",
    "})\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Reshape the data such that it becomes tidy and fill any missing value in the value column with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise: Real-world data tidying problem\n",
    "\n",
    "To finish off the chapter, let's pull together everything you've learned to tackle a realistic data tidying problem. The `tidyr::who` dataset contains tuberculosis (TB) cases broken down by year, country, age, gender, and diagnosis method. The data comes from the [2014 World Health Organization Global Tuberculosis Report](http://www.who.int/tb/country/data/download/en/).\n",
    "\n",
    "There's a wealth of epidemiological information in this dataset, but it's challenging to work with the data in the form that it's provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who = pd.read_csv(\"https://raw.githubusercontent.com/vhaus63/ids_data/refs/heads/main/who.csv\")\n",
    "# Fix the Namibia NA iso code.\n",
    "who.loc[who.iso2.isna(),'iso2'] = \"NA\"\n",
    "\n",
    "who"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very typical real-life example dataset. It contains redundant columns, odd variable codes, and many missing values. In short, `who` is messy, and we'll need multiple steps to tidy it. \n",
    "\n",
    "This endeavor will be part of the following exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/d3.png' style='width:80%; float:left;' />"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "rise": {
   "custom_css": "./rise.css",
   "enable_chalkboard": false,
   "overlay": "<div class='background'></div><div class='header'>Introduction to Data Science (IDS)</div><div class='logo'><img src='images/d3logo.png'></div><div class='bar'></div>",
   "scroll": true,
   "slideNumber": true,
   "start_slideshow_at": "selected"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
